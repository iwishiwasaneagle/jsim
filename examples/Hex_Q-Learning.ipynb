{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hex Tiled Q-Learning SAR example\n",
    "\n",
    "The challenge in this example is implementing a Q-Learning search algorithm in a hexagonal tiled environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"../src\")) # run from within examples folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from copy import copy\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from jsim.Environment import HexEnvironment, HexDirections\n",
    "from jsim.Agent import Agent\n",
    "from jsim.Simulation import Simulation\n",
    "from jsim.Environment.HexEnvironment.HexCoords import OffsetCoord\n",
    "from jsim.Meta import State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QHexEnv(HexEnvironment):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.pdm = self._generate_pdm()\n",
    "        self.n_bins = 4\n",
    "        self.digitized_pdm = self._encode_pdm(n=self.n_bins)\n",
    "        c = np.arange(0,1+np.max(self.digitized_pdm))\n",
    "        u,v,w,x,y,z = np.meshgrid(c,c,c,c,c,c) # one for each direction (6)\n",
    "        u,v,w,x,y,z = u.flatten(), v.flatten(), w.flatten(), x.flatten(), y.flatten(), z.flatten()\n",
    "        self.possible_states = {(a,b,c,d,e,f): int(np.where((u==a)&(v==b)&(w==c)&(x==d)&(y==e)&(z==f))[0]) for a,b,c,d,e,f in zip(u,v,w,x,y,z)}\n",
    "\n",
    "\n",
    "    def _generate_pdm(self, N:int=5):\n",
    "        x, y = np.meshgrid(np.arange(self.shape[0]), np.arange(self.shape[1]))\n",
    "\n",
    "        pdm = np.zeros(self.shape)\n",
    "\n",
    "        for _ in range(N): # Generate N gaussians\n",
    "            A = max(np.random.rand()*2,1)\n",
    "            a = np.random.rand()*0.03\n",
    "            b = 0\n",
    "            c = np.random.rand()*0.03\n",
    "            x0 = np.random.uniform(0,self.shape[0]) # Centre of gaussian\n",
    "            y0 = np.random.uniform(0,self.shape[1])\n",
    "\n",
    "            pdm += A*np.exp(-(a*(x-x0)**2+2*b*(x-x0)*(y-y0)+c*(y-y0)**2))\n",
    "\n",
    "        return pdm\n",
    "\n",
    "    def _encode_pdm(self, n: int) -> np.ndarray:\n",
    "        n_bins = n\n",
    "        bins = np.arange(0,np.max(self.pdm), np.max(self.pdm)/n_bins)\n",
    "        return np.digitize(self.pdm, bins)\n",
    "\n",
    "    def _state_from_list(self, l):\n",
    "        assert len(l) == len(HexDirections)\n",
    "        return self.possible_states[tuple(l)]\n",
    "\n",
    "\n",
    "    def _evaluate_position(self, pos: OffsetCoord) -> int:\n",
    "        return self.digitized_pdm[pos.row][pos.col]\n",
    "\n",
    "    def reset(self, agent_p: OffsetCoord) -> int:\n",
    "        #self.pdm = self._generate_pdm()\n",
    "        #self.digitized_pdm = self._encode_pdm(n=self.n_bins)\n",
    "        return self._evaluate_position(agent_p)\n",
    "\n",
    "    def step(self, agent_s: OffsetCoord) -> tuple[int, float]:\n",
    "        reward = self._evaluate_position(agent_s)\n",
    "        neighbors = self.neighbors_coord(agent_s)\n",
    "\n",
    "        values_at_neighbors = self._state_from_list([self._evaluate_position(n) for n in neighbors])\n",
    "\n",
    "        return values_at_neighbors, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QAgent(Agent):\n",
    "    def __init__(self, penv: QHexEnv = None) -> None:\n",
    "        self.state = OffsetCoord(col=0,row=0)\n",
    "        self.penv = penv\n",
    "\n",
    "        self.qtable = np.zeros((len(self.penv.possible_states),6))\n",
    "\n",
    "    def policy(self, pnext_s: int) -> HexDirections:\n",
    "        epsilon = 0.2\n",
    "        if np.random.uniform(0,1) < epsilon:\n",
    "            idx = np.random.randint(0,6)\n",
    "        else:\n",
    "            idx = np.argmax(self.qtable[pnext_s])\n",
    "        return HexDirections(idx)\n",
    "\n",
    "    def step(self, pnext_s: int) -> HexDirections:\n",
    "        return self.policy(pnext_s)\n",
    "\n",
    "    def learn(self, reward: float, state: int, next_state: int,  action: HexDirections) -> None:\n",
    "        alpha = 0.1\n",
    "        gamma = 0.9\n",
    "\n",
    "        reward = -reward\n",
    "\n",
    "        new_value = (1-alpha) * self.qtable[state,action] + alpha * (reward+gamma*np.max(self.qtable[next_state]))\n",
    "\n",
    "        self.qtable[state][action] = new_value\n",
    "\n",
    "\n",
    "    def update(self, pa: HexDirections) -> OffsetCoord:\n",
    "        if not hasattr(self,'state'):\n",
    "            logger.error(f\"Reset has not been called as {hasattr(self,'state')=}\")\n",
    "            raise Exception\n",
    "\n",
    "        next_state = QHexEnv.neighbor_coord(self.state, pa)\n",
    "        self.state = next_state\n",
    "\n",
    "        return copy(self.state)\n",
    "\n",
    "    def reset(self, ps: OffsetCoord, vicinity: int) -> tuple[HexDirections, OffsetCoord]:\n",
    "        self.state = copy(ps)\n",
    "        return self.policy(vicinity), self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QSim(Simulation):\n",
    "    agent: QAgent\n",
    "    env: QHexEnv\n",
    "\n",
    "    def __init__(self, initial_pos=OffsetCoord(col=5,row=5)) -> None:\n",
    "        self.env = QHexEnv(psim=self)\n",
    "        self.agent = QAgent(penv=self.env)\n",
    "\n",
    "        self.initial_agent_s = initial_pos\n",
    "\n",
    "        self.data_store = {'env_s':[],'agent_s':[],'agent_a':[],'reward':[]}\n",
    "        self.long_term_ds = {}\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.vicinity_pdm = self.env.reset(self.initial_agent_s)\n",
    "        self.agent_a, self.agent_s = self.agent.reset(copy(self.initial_agent_s),self.vicinity_pdm)\n",
    "        self.data_store = {'env_s':[],'agent_s':[],'agent_a':[],'reward':[]}\n",
    "\n",
    "    def trials(self, num_trials: int, max_num_steps: int):\n",
    "        for i in range(num_trials):\n",
    "            try:\n",
    "                self.steps(max_num_steps)\n",
    "                logger.info(f\"Trial = {i} | Max number of steps ({max_num_steps}) reached \")\n",
    "            except IndexError:\n",
    "                logger.info(f\"Trial = {i} | Agent went out of bounds, reseting\")\n",
    "            finally:\n",
    "                self.long_term_ds[i] = copy(self.data_store)\n",
    "\n",
    "    def steps(self, num_steps: int) -> None:\n",
    "        self.reset()\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            vicinity_pdm, reward = self.env.step(self.agent_s)\n",
    "\n",
    "            self.collect_data(vicinity_pdm, self.agent_a, self.agent_s, reward)\n",
    "\n",
    "            agent_a = self.agent.step(vicinity_pdm)\n",
    "            agent_s = self.agent.update(agent_a)\n",
    "\n",
    "            self.agent.learn(reward, self.vicinity_pdm, vicinity_pdm, agent_a)\n",
    "\n",
    "            self.agent_s = agent_s\n",
    "            self.agent_a = agent_a\n",
    "            self.vicinity_pdm = vicinity_pdm\n",
    "\n",
    "\n",
    "\n",
    "    def collect_data(self, env_s: int, agent_a: HexDirections, agent_s: OffsetCoord, reward: float) -> None:\n",
    "        self.data_store['env_s'].append(copy(env_s))\n",
    "        self.data_store['agent_a'].append(copy(agent_a))\n",
    "        self.data_store['agent_s'].append(copy(agent_s))\n",
    "        self.data_store['reward'].append(copy(reward))\n",
    "\n",
    "    def plot(self):\n",
    "        fig, (ax1, ax2) = plt.subplots(2,1, gridspec_kw={'height_ratios': [1, 3]}, figsize=(8, 6), dpi=80)\n",
    "\n",
    "        t = np.arange(0,len(self.long_term_ds))\n",
    "\n",
    "        # Reward over time\n",
    "        ax1.bar(self.long_term_ds.keys(), [np.sum(self.long_term_ds[ds]['reward']) for ds in self.long_term_ds])\n",
    "        ax1.set_ylabel('Total reward')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "\n",
    "        # Show pdm and path\n",
    "        xy = [HexEnvironment.offset_to_pixel(f) for f in self.data_store['agent_s']]\n",
    "        x = [f.x for f in xy]\n",
    "        y = [f.y for f in xy]\n",
    "\n",
    "        pdm = self.env.pdm\n",
    "        for p in self.env.as_mpl_polygons(cmap=mpl.cm.get_cmap('gray')):\n",
    "            ax2.add_patch(p)\n",
    "\n",
    "        ax2.plot(x,y)\n",
    "        ax2.scatter(x[0],y[0],label='Start')\n",
    "        ax2.scatter(x[-1],y[-1],label='End')\n",
    "        ax2.set_ylabel('y')\n",
    "        ax2.set_xlabel('x')\n",
    "        ax2.legend()\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sim = QSim()\n",
    "\n",
    "sim.trials(50,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sim.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
